{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import utils\n",
    " \n",
    "BEST_ALFA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class New_Splitted_Ensemble(object):\n",
    "    \n",
    "    def fit(self, URM_csr, URM_train, ICM_csr, alfa):\n",
    "        transformer = TfidfTransformer()\n",
    "        transformer.fit(URM_train)\n",
    "        tf_idf_csr = transformer.transform(URM_csr)\n",
    "\n",
    "        IRM = sparse.csr_matrix(tf_idf_csr.transpose())\n",
    "        \n",
    "        csr_similarities = sparse.csr_matrix(cosine_similarity(IRM, dense_output=False))\n",
    "        \n",
    "\n",
    "        transformer.fit(ICM_csr)\n",
    "        tf_idf_icm = transformer.transform(ICM_csr)\n",
    "        icm_similarities = sparse.csr_matrix(cosine_similarity(tf_idf_icm, dense_output=False))\n",
    "        \n",
    "        print(\"COMPUTING ENSEMBLE SIMILARITIES\")\n",
    "        self.item_similarities = alfa*csr_similarities + (1-alfa)*icm_similarities        \n",
    "        self.URM_csr = URM_csr\n",
    "        \n",
    "    \n",
    "    def recommend(self, user_id, at=10, remove_seen=True):\n",
    "        \n",
    "        user = self.URM_csr.getrow(user_id)\n",
    "        itemPopularity = user.dot(self.item_similarities)\n",
    "        popularItems = np.argsort(np.array(itemPopularity.todense())[0])\n",
    "        popularItems = np.flip(popularItems, axis = 0)\n",
    "\n",
    "        if remove_seen:\n",
    "            unseen_items_mask = np.in1d(popularItems, self.URM_csr[user_id].indices,\n",
    "                                        assume_unique=True, invert = True)\n",
    "\n",
    "            unseen_items = popularItems[unseen_items_mask]\n",
    "            \n",
    "            recommended_items = unseen_items[0:at]\n",
    "\n",
    "        else:\n",
    "            recommended_items = popularItems[0:at]\n",
    "            \n",
    "        recommended_items = \" \".join(str(i) for i in recommended_items)\n",
    "        return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('../input/tracks.csv')\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "target = pd.read_csv('../input/target_playlists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuse\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\sparse\\compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "training_set_ns = utils.build_urm_csr(train)\n",
    "icm_csr = utils.build_icm_csr(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_playlists = np.genfromtxt('../input/target_playlists.csv', delimiter = ',', dtype=int)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrencies = training_set_ns.getnnz(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = np.where(occurrencies < 15)\n",
    "mask2 = np.where((occurrencies >= 15) & (occurrencies < 30))\n",
    "mask3 = np.where(occurrencies >= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_train = sparse.csr_matrix(training_set_ns.shape, dtype = np.float32)\n",
    "middle_train = sparse.csr_matrix(training_set_ns.shape, dtype = np.float32)\n",
    "above_train = sparse.csr_matrix(training_set_ns.shape, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_train = training_set_ns[mask1]\n",
    "middle_train = training_set_ns[mask2]\n",
    "above_train = training_set_ns[mask3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITTING...\n",
      "COMPUTING ENSEMBLE SIMILARITIES\n",
      "COMPUTING ENSEMBLE SIMILARITIES\n",
      "COMPUTING ENSEMBLE SIMILARITIES\n",
      "RECOMMENDING...\n",
      "SAVING RESULT TO 'sample_submission.csv'\n"
     ]
    }
   ],
   "source": [
    "ensemble1 = New_Splitted_Ensemble()\n",
    "ensemble2 = New_Splitted_Ensemble()\n",
    "ensemble3 = New_Splitted_Ensemble()\n",
    "\n",
    "print(\"FITTING...\")\n",
    "ensemble1.fit(training_set_ns, below_train, icm_csr, alfa = BEST_ALFA)\n",
    "ensemble2.fit(training_set_ns, middle_train, icm_csr, alfa = BEST_ALFA)\n",
    "ensemble3.fit(training_set_ns, above_train, icm_csr, alfa = BEST_ALFA)\n",
    "\n",
    "result = []\n",
    "    \n",
    "print(\"RECOMMENDING...\")\n",
    "for elem in target_playlists:\n",
    "    if(elem in mask1[0]):\n",
    "        recommendation = ensemble1.recommend(elem)\n",
    "    elif(elem in mask2[0]):\n",
    "        recommendation = ensemble2.recommend(elem)\n",
    "    elif(elem in mask3[0]):\n",
    "        recommendation = ensemble3.recommend(elem)\n",
    "    else:\n",
    "        print(\"ERROR: CAN'T FIND PLAYLIST NUMBER \" + str(elem) + \" IN ANY OF THE 3 SETS\")\n",
    "    temp = [elem,recommendation]\n",
    "    result.append(temp)\n",
    "    \n",
    "print(\"SAVING RESULT TO 'sample_submission.csv'\")\n",
    "rec = pd.DataFrame(result)\n",
    "rec.to_csv(\"sample_submission.csv\", index = False, header = [\"playlist_id\", \"track_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
