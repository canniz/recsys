{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLIM_BPR.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import utils\n",
    "import CF_CBF_Ensemble as cf_cbf\n",
    " \n",
    "BEST_ALFA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class New_Splitted_Ensemble(object):\n",
    "    \n",
    "    def fit(self, URM_csr, URM_train, ICM_csr, slim_recommender, alfa):\n",
    "        self.slim_recommender = slim_recommender\n",
    "        transformer = TfidfTransformer()\n",
    "        transformer.fit(URM_train)\n",
    "        tf_idf_csr = transformer.transform(URM_csr)\n",
    "\n",
    "        IRM = sparse.csr_matrix(tf_idf_csr.transpose())\n",
    "        \n",
    "        csr_similarities = sparse.csr_matrix(cosine_similarity(IRM, dense_output=False))\n",
    "        \n",
    "\n",
    "        transformer.fit(ICM_csr)\n",
    "        tf_idf_icm = transformer.transform(ICM_csr)\n",
    "        icm_similarities = sparse.csr_matrix(cosine_similarity(tf_idf_icm, dense_output=False))\n",
    "        \n",
    "        print(\"COMPUTING ENSEMBLE SIMILARITIES\")\n",
    "        self.item_similarities = alfa*csr_similarities + (1-alfa)*icm_similarities        \n",
    "        self.URM_csr = URM_csr\n",
    "        \n",
    "    \n",
    "    def recommend(self, user_id, at=10, remove_seen=True):\n",
    "        \n",
    "        user = self.URM_csr.getrow(user_id)\n",
    "        itemPopularity = user.dot(self.item_similarities)\n",
    "        slimPopularity = self.slim_recommender.compute_item_score(user_id)\n",
    "        item_popularity = itemPopularity*self.beta + slimPopularity*(1-self.beta)\n",
    "        popularItems = np.argsort(np.array(itemPopularity.todense())[0])\n",
    "        popularItems = np.flip(popularItems, axis = 0)\n",
    "\n",
    "        if remove_seen:\n",
    "            unseen_items_mask = np.in1d(popularItems, self.URM_csr[user_id].indices,\n",
    "                                        assume_unique=True, invert = True)\n",
    "\n",
    "            unseen_items = popularItems[unseen_items_mask]\n",
    "            \n",
    "            recommended_items = unseen_items[0:at]\n",
    "\n",
    "        else:\n",
    "            recommended_items = popularItems[0:at]\n",
    "            \n",
    "        #recommended_items = \" \".join(str(i) for i in recommended_items)\n",
    "        return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('../input/tracks.csv')\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "target = pd.read_csv('../input/target_playlists.csv')\n",
    "sequential = pd.read_csv('../input/train_sequential.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuse\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\sparse\\compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "not_sequential = utils.build_urm_csr(train)\n",
    "training_set_ns, test_set_ns = utils.split(not_sequential)\n",
    "#sequential = utils.build_urm_csr(sequential)\n",
    "icm_csr = utils.build_icm_csr(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_playlists = np.unique(test_set_ns.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrencies = training_set_ns.getnnz(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = np.where(occurrencies < 15)\n",
    "mask2 = np.where((occurrencies >= 15) & (occurrencies < 30))\n",
    "mask3 = np.where(occurrencies >= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_1 = np.intersect1d(mask1, test_set_playlists)\n",
    "test_set_2 = np.intersect1d(mask2, test_set_playlists)\n",
    "test_set_3 = np.intersect1d(mask3, test_set_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_train = sparse.csr_matrix(not_sequential.shape, dtype = np.float32)\n",
    "middle_train = sparse.csr_matrix(not_sequential.shape, dtype = np.float32)\n",
    "above_train = sparse.csr_matrix(not_sequential.shape, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_train = training_set_ns[mask1]\n",
    "middle_train = training_set_ns[mask2]\n",
    "above_train = training_set_ns[mask3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIM_BPR_Cython: Estimated memory required for similarity matrix of 20635 items is 1703.21 MB\n",
      "FITTING SLIM...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SLIM_BPR.Cython.SLIM_BPR_Cython_Epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d63335d64e9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FITTING SLIM...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mslim1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msgd_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtopK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mbetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\recsys\\Notebooks\\SLIM_BPR\\Cython\\SLIM_BPR_Cython.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, logFile, batch_size, lambda_i, lambda_j, learning_rate, topK, sgd_mode, gamma, beta_1, beta_2, stop_on_validation, lower_validatons_allowed, validation_metric, evaluator_object, validation_every_n)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m# Import compiled module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mSLIM_BPR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSLIM_BPR_Cython_Epoch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSLIM_BPR_Cython_Epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# Select only positive interactions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'SLIM_BPR.Cython.SLIM_BPR_Cython_Epoch'"
     ]
    }
   ],
   "source": [
    "ensemble1 = New_Splitted_Ensemble()\n",
    "ensemble2 = New_Splitted_Ensemble()\n",
    "ensemble3 = New_Splitted_Ensemble()\n",
    "slim1 = SLIM_BPR_Cython(below_train,recompile_cython=False,positive_threshold=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FITTING SLIM...\")\n",
    "slim1.fit(epochs=150, batch_size=5,sgd_mode='adam',learning_rate=1e-4,topK=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "maps1 = []\n",
    "maps2 = []\n",
    "maps3 = []\n",
    "for beta in betas:\n",
    "    print(\"FITTING WITH ALPHA = \" + str(beta))\n",
    "    ensemble1.fit(training_set_ns, below_train, icm_csr, slim1, alfa = BEST_ALFA)\n",
    "    ensemble2.fit(training_set_ns, middle_train, icm_csr, slim1, alfa = BEST_ALFA)\n",
    "    ensemble3.fit(training_set_ns, above_train, icm_csr, slim1, alfa = BEST_ALFA)\n",
    "    print(\"EVALUATING FIRST ALGORITHM\")\n",
    "    maps1.append(utils.evaluate_algorithm(test_set_ns, ensemble1, test_set_1))\n",
    "    print(\"EVALUATING SECOND ALGORITHM\")\n",
    "    maps2.append(utils.evaluate_algorithm(test_set_ns, ensemble2, test_set_2))\n",
    "    print(\"EVALUATING THIRD ALGORITHM\")\n",
    "    maps3.append(utils.evaluate_algorithm(test_set_ns, ensemble3, test_set_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
