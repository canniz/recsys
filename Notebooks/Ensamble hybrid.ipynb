{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('../input/tracks.csv')\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "target = pd.read_csv('../input/target_playlists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "icm_csr = utils.build_icm_csr(tracks)\n",
    "urm_csr = utils.build_urm_csr(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Notebooks_utils.data_splitter import train_test_holdout\n",
    "\n",
    "URM_train, URM_test = train_test_holdout(urm_csr, train_perc = 0.8)\n",
    "URM_train, URM_validation = train_test_holdout(URM_train, train_perc = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50446x20635 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 872677 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " URM_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50446x20635 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 242167 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50446x20635 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 96947 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ParameterTuning.AbstractClassSearch import EvaluatorWrapper\n",
    "from Base.Evaluation.Evaluator import SequentialEvaluator\n",
    "\n",
    "evaluator_validation = SequentialEvaluator(URM_validation, cutoff_list=[5])\n",
    "evaluator_test = SequentialEvaluator(URM_test, cutoff_list=[5, 10])\n",
    "\n",
    "evaluator_validation = EvaluatorWrapper(evaluator_validation)\n",
    "evaluator_test = EvaluatorWrapper(evaluator_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from ParameterTuning.BayesianSearch import BayesianSearch\n",
    "\n",
    "\n",
    "recommender_class = ItemKNNCFRecommender\n",
    "\n",
    "from SLIM_BPR.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "from ParameterTuning.BayesianSearch import BayesianSearch\n",
    "\n",
    "\n",
    "recommender_class_slim = SLIM_BPR_Cython\n",
    "\n",
    "parameterSearch = BayesianSearch(recommender_class_slim,\n",
    "                                 evaluator_validation=evaluator_validation,\n",
    "                                 evaluator_test=evaluator_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ParameterTuning.AbstractClassSearch import DictionaryKeys\n",
    "\n",
    "hyperparamethers_range_dictionary = {}\n",
    "hyperparamethers_range_dictionary[\"topK\"] = [5, 10, 20, 50, 100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "hyperparamethers_range_dictionary[\"shrink\"] = [0, 5, 10, 50, 100, 200, 300, 500, 1000]\n",
    "hyperparamethers_range_dictionary[\"similarity\"] = [\"cosine\"]\n",
    "hyperparamethers_range_dictionary[\"normalize\"] = [True, False]\n",
    "\n",
    "\n",
    "recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "                         DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "                         DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                         DictionaryKeys.FIT_KEYWORD_ARGS: dict(),\n",
    "                         DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "output_root_path = \"result_experiments/\"\n",
    "\n",
    "import os\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_root_path):\n",
    "    os.makedirs(output_root_path)\n",
    "    \n",
    "\n",
    "output_root_path += recommender_class.RECOMMENDER_NAME\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   normalize |    shrink |   similarity |      topK | \n",
      "BayesianSearch: Testing config: {'topK': 200, 'shrink': 1000, 'similarity': 'cosine', 'normalize': True} - Exception MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n",
      "\n",
      "    1 | 00m00s | \u001b[35m      -inf\u001b[0m | \u001b[32m     0.1395\u001b[0m | \u001b[32m   7.6326\u001b[0m | \u001b[32m      0.0000\u001b[0m | \u001b[32m   6.1517\u001b[0m | \n",
      "BayesianSearch: Testing config: {'topK': 100, 'shrink': 300, 'similarity': 'cosine', 'normalize': False} - Exception MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n",
      "\n",
      "    2 | 00m00s |       -inf |      0.8048 |    6.0024 |       0.0000 |    3.7598 | \n",
      "BayesianSearch: Testing config: {'topK': 100, 'shrink': 10, 'similarity': 'cosine', 'normalize': False} - Exception MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n",
      "\n",
      "    3 | 00m00s |       -inf |      0.9593 |    1.7810 |       0.0000 |    4.1468 | \n",
      "BayesianSearch: Testing config: {'topK': 300, 'shrink': 300, 'similarity': 'cosine', 'normalize': False} - Exception MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n",
      "\n",
      "    4 | 00m00s |       -inf |      0.7414 |    6.1115 |       0.0000 |    6.6483 | \n",
      "BayesianSearch: Testing config: {'topK': 300, 'shrink': 300, 'similarity': 'cosine', 'normalize': False} - Exception MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n",
      "\n",
      "    5 | 00m00s |       -inf |      0.8293 |    6.4756 |       0.0000 |    6.5540 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/ParameterTuning/BayesianSearch.py\", line 222, in runSingleCase_param_parsed\n",
      "    **dictionary[DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS])\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/SLIM_BPR/Cython/SLIM_BPR_Cython.py\", line 65, in __init__\n",
      "    assert self.URM_mask.nnz > 0, \"MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\"\n",
      "AssertionError: MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/ParameterTuning/BayesianSearch.py\", line 222, in runSingleCase_param_parsed\n",
      "    **dictionary[DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS])\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/SLIM_BPR/Cython/SLIM_BPR_Cython.py\", line 65, in __init__\n",
      "    assert self.URM_mask.nnz > 0, \"MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\"\n",
      "AssertionError: MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/ParameterTuning/BayesianSearch.py\", line 222, in runSingleCase_param_parsed\n",
      "    **dictionary[DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS])\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/SLIM_BPR/Cython/SLIM_BPR_Cython.py\", line 65, in __init__\n",
      "    assert self.URM_mask.nnz > 0, \"MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\"\n",
      "AssertionError: MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/ParameterTuning/BayesianSearch.py\", line 222, in runSingleCase_param_parsed\n",
      "    **dictionary[DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS])\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/SLIM_BPR/Cython/SLIM_BPR_Cython.py\", line 65, in __init__\n",
      "    assert self.URM_mask.nnz > 0, \"MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\"\n",
      "AssertionError: MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/ParameterTuning/BayesianSearch.py\", line 222, in runSingleCase_param_parsed\n",
      "    **dictionary[DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS])\n",
      "  File \"/home/antonio/Documents/recsys/Notebooks/SLIM_BPR/Cython/SLIM_BPR_Cython.py\", line 65, in __init__\n",
      "    assert self.URM_mask.nnz > 0, \"MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\"\n",
      "AssertionError: MatrixFactorization_Cython: URM_train_positive is empty, positive threshold is too high\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-84ff8da3c42e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                          \u001b[0mn_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_cases\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0moutput_root_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_root_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                          metric=metric_to_optimize)\n\u001b[0m",
      "\u001b[0;32m~/Documents/recsys/Notebooks/ParameterTuning/BayesianSearch.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, dictionary, metric, init_points, n_cases, output_root_path, parallelPoolSize, parallelize, save_model)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbayesian_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mbest_solution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbayesian_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/recsys/Notebooks/ParameterTuning/BayesianOptimization_master/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# Find unique rows of X to avoid GP from breaking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Finding argmax of the acquisition function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# Normalize target value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[0;32m--> 750\u001b[0;31m                         dtype=None)\n\u001b[0m\u001b[1;32m    751\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 568\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "n_cases = 5\n",
    "metric_to_optimize = \"MAP\"\n",
    "\n",
    "best_parameters = parameterSearch.search(recommenderDictionary,\n",
    "                                         n_cases = n_cases,\n",
    "                                         output_root_path = output_root_path,\n",
    "                                         metric=metric_to_optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ItemKNNCFRecommender' has no attribute 'sparse_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ec4e1949d75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommender_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score_user_based\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommender_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/recsys/Notebooks/Base/SimilarityMatrixRecommender.py\u001b[0m in \u001b[0;36mcompute_score_user_based\u001b[0;34m(self, user_id)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_score_user_based\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_sparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURM_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ItemKNNCFRecommender' has no attribute 'sparse_weights'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemKNNCF = ItemKNNCFRecommender(URM_train)\n",
    "itemKNNCF.fit(**best_parameters)\n",
    "\n",
    "\n",
    "from GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "\n",
    "P3alpha = P3alphaRecommender(URM_train)\n",
    "P3alpha.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemKNNCF.W_sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3alpha.W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Base.Recommender import Recommender\n",
    "from Base.Recommender_utils import check_matrix, similarityMatrixTopK\n",
    "from Base.SimilarityMatrixRecommender import SimilarityMatrixRecommender\n",
    "\n",
    "\n",
    "class ItemKNNSimilarityHybridRecommender(SimilarityMatrixRecommender, Recommender):\n",
    "    \"\"\" ItemKNNSimilarityHybridRecommender\n",
    "    Hybrid of two similarities S = S1*alpha + S2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ItemKNNSimilarityHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, Similarity_1, Similarity_2, sparse_weights=True):\n",
    "        super(ItemKNNSimilarityHybridRecommender, self).__init__()\n",
    "\n",
    "        if Similarity_1.shape != Similarity_2.shape:\n",
    "            raise ValueError(\"ItemKNNSimilarityHybridRecommender: similarities have different size, S1 is {}, S2 is {}\".format(\n",
    "                Similarity_1.shape, Similarity_2.shape\n",
    "            ))\n",
    "\n",
    "        # CSR is faster during evaluation\n",
    "        self.Similarity_1 = check_matrix(Similarity_1.copy(), 'csr')\n",
    "        self.Similarity_2 = check_matrix(Similarity_2.copy(), 'csr')\n",
    "\n",
    "        self.URM_train = check_matrix(URM_train.copy(), 'csr')\n",
    "\n",
    "        self.sparse_weights = sparse_weights\n",
    "\n",
    "\n",
    "    def fit(self, topK=100, alpha = 0.5):\n",
    "\n",
    "        self.topK = topK\n",
    "        self.alpha = alpha\n",
    "\n",
    "        W = self.Similarity_1*self.alpha + self.Similarity_2*(1-self.alpha)\n",
    "\n",
    "        if self.sparse_weights:\n",
    "            self.W_sparse = similarityMatrixTopK(W, forceSparseOutput=True, k=self.topK)\n",
    "        else:\n",
    "            self.W = similarityMatrixTopK(W, forceSparseOutput=False, k=self.topK)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybridrecommender = ItemKNNSimilarityHybridRecommender(URM_train, itemKNNCF.W_sparse, P3alpha.W_sparse)\n",
    "hybridrecommender.fit(alpha = 0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_validation.evaluateRecommender(hybridrecommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixFactorization.PureSVD import PureSVDRecommender\n",
    "\n",
    "pureSVD = PureSVDRecommender(URM_train)\n",
    "pureSVD.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ItemKNNScoresHybridRecommender(Recommender):\n",
    "    \"\"\" ItemKNNScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ItemKNNScoresHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, Recommender_1, Recommender_2):\n",
    "        super(ItemKNNScoresHybridRecommender, self).__init__()\n",
    "\n",
    "        self.URM_train = check_matrix(URM_train.copy(), 'csr')\n",
    "        self.Recommender_1 = Recommender_1\n",
    "        self.Recommender_2 = Recommender_2\n",
    "        \n",
    "        self.compute_item_score = self.compute_score_hybrid\n",
    "        \n",
    "  \n",
    "    def fit(self, alpha = 0.5):\n",
    "\n",
    "        self.alpha = alpha      \n",
    "\n",
    "\n",
    "    def compute_score_hybrid(self, user_id_array):\n",
    "        \n",
    "        item_weights_1 = self.Recommender_1.compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.Recommender_2.compute_item_score(user_id_array)\n",
    "\n",
    "        item_weights = item_weights_1*self.alpha + item_weights_2*(1-self.alpha)\n",
    "\n",
    "        return item_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybridrecommender = ItemKNNScoresHybridRecommender(URM_train, itemKNNCF, pureSVD)\n",
    "hybridrecommender.fit(alpha = 0.8)\n",
    "\n",
    "evaluator_validation.evaluateRecommender(hybridrecommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_train = sps.csr_matrix(URM_train)\n",
    "\n",
    "profile_length = np.ediff1d(URM_train.indptr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = int(len(profile_length)*0.05)\n",
    "block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_users = np.argsort(profile_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_id in range(0, 10):\n",
    "    \n",
    "    start_pos = group_id*block_size\n",
    "    end_pos = min((group_id+1)*block_size, len(profile_length))\n",
    "    \n",
    "    users_in_group = sorted_users[start_pos:end_pos]\n",
    "    \n",
    "    users_in_group_p_len = profile_length[users_in_group]\n",
    "    \n",
    "    print(\"Group {}, average p.len {:.2f}, min {}, max {}\".format(group_id, \n",
    "        users_in_group_p_len.mean(), users_in_group_p_len.min(), users_in_group_p_len.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Base.NonPersonalizedRecommender import TopPop\n",
    "\n",
    "topPop = TopPop(URM_train)\n",
    "topPop.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KNN.ItemKNNCBFRecommender import ItemKNNCBFRecommender\n",
    "\n",
    "\n",
    "recommender_class = ItemKNNCBFRecommender\n",
    "\n",
    "parameterSearch = BayesianSearch(recommender_class,\n",
    "                                 evaluator_validation=evaluator_validation,\n",
    "                                 evaluator_test=evaluator_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparamethers_range_dictionary = {}\n",
    "hyperparamethers_range_dictionary[\"topK\"] = [5, 10, 20, 50, 100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "hyperparamethers_range_dictionary[\"shrink\"] = [0, 10, 50, 100, 200, 300, 500, 1000]\n",
    "hyperparamethers_range_dictionary[\"similarity\"] = [\"cosine\"]\n",
    "hyperparamethers_range_dictionary[\"normalize\"] = [True, False]\n",
    "\n",
    "\n",
    "recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [icm_csr, URM_train],\n",
    "                         DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "                         DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                         DictionaryKeys.FIT_KEYWORD_ARGS: dict(),\n",
    "                         DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "output_root_path = \"result_experiments/\"\n",
    "\n",
    "import os\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_root_path):\n",
    "    os.makedirs(output_root_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "n_cases = 2\n",
    "metric_to_optimize = \"MAP\"\n",
    "\n",
    "best_parameters_ItemKNNCBF = parameterSearch.search(recommenderDictionary,\n",
    "                                                 n_cases = n_cases,\n",
    "                                                 output_root_path = output_root_path,\n",
    "                                                 metric=metric_to_optimize)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemKNNCBF = ItemKNNCBFRecommender(icm_csr, URM_train)\n",
    "itemKNNCBF.fit(**best_parameters_ItemKNNCBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MAP_itemKNNCF_per_group = []\n",
    "MAP_itemKNNCBF_per_group = []\n",
    "MAP_pureSVD_per_group = []\n",
    "MAP_topPop_per_group = []\n",
    "cutoff = 10\n",
    "\n",
    "for group_id in range(0, 10):\n",
    "    \n",
    "    start_pos = group_id*block_size\n",
    "    end_pos = min((group_id+1)*block_size, len(profile_length))\n",
    "    \n",
    "    users_in_group = sorted_users[start_pos:end_pos]\n",
    "    \n",
    "    users_in_group_p_len = profile_length[users_in_group]\n",
    "    \n",
    "    print(\"Group {}, average p.len {:.2f}, min {}, max {}\".format(group_id, \n",
    "        users_in_group_p_len.mean(), users_in_group_p_len.min(), users_in_group_p_len.max()))\n",
    "    \n",
    "    \n",
    "    users_not_in_group_flag = np.isin(sorted_users, users_in_group, invert = True)\n",
    "    users_not_in_group = sorted_users[users_not_in_group_flag]\n",
    "    \n",
    "    evaluator_test = SequentialEvaluator(URM_test, cutoff_list=[cutoff], ignore_users = users_not_in_group)\n",
    "    \n",
    "    \n",
    "    results, _ = evaluator_test.evaluateRecommender(itemKNNCF)\n",
    "    MAP_itemKNNCF_per_group.append(results[cutoff][\"MAP\"])\n",
    " \n",
    "    results, _ = evaluator_test.evaluateRecommender(pureSVD)\n",
    "    MAP_pureSVD_per_group.append(results[cutoff][\"MAP\"])\n",
    "\n",
    "    results, _ = evaluator_test.evaluateRecommender(itemKNNCBF)\n",
    "    MAP_itemKNNCBF_per_group.append(results[cutoff][\"MAP\"])\n",
    "\n",
    "    results, _ = evaluator_test.evaluateRecommender(topPop)\n",
    "    MAP_topPop_per_group.append(results[cutoff][\"MAP\"])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline  \n",
    "\n",
    "pyplot.plot(MAP_itemKNNCF_per_group, label=\"itemKNNCF\")\n",
    "pyplot.plot(MAP_itemKNNCBF_per_group, label=\"itemKNNCBF\")\n",
    "pyplot.plot(MAP_pureSVD_per_group, label=\"pureSVD\")\n",
    "pyplot.plot(MAP_topPop_per_group, label=\"topPop\")\n",
    "pyplot.ylabel('MAP')\n",
    "pyplot.xlabel('User Group')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_test.evaluateRecommender(itemKNNCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_test.evaluateRecommender(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
