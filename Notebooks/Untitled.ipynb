{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "TEST_SET_THRESHOLD = 10\n",
    "TEST_SET_HOLDOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('../input/tracks.csv')\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "target = pd.read_csv('../input/target_playlists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_urm_csr(data):\n",
    "    fill_data = np.ones(data.shape[0])\n",
    "    #posso usare gli id direttamente solo perchè come già detto sono consistenti\n",
    "    row = data['playlist_id'].values\n",
    "    col = data['track_id'].values\n",
    "    n_pl = np.amax(data['playlist_id']) + 1\n",
    "    n_tr = np.amax(data['track_id']) + 1\n",
    "    \n",
    "    return sparse.csr_matrix((fill_data, (row, col)), dtype=np.int32, shape=(n_pl, n_tr))\n",
    "\n",
    "def build_icm_csr(data):\n",
    "    classify_durations(data)\n",
    "    \n",
    "    albums_id = data['album_id']\n",
    "    artists_id = data['artist_id']\n",
    "    durations = data['duration_sec']\n",
    "    tracks = data['track_id']\n",
    "    \n",
    "    albums_max = np.amax(albums_id)\n",
    "    artists_max = np.amax(artists_id)\n",
    "    durations_max = np.amax(durations)\n",
    "    number_of_songs = data.shape[0]\n",
    "    \n",
    "    icm_csr_matrix = sparse.csr_matrix((number_of_songs, albums_max + artists_max + durations_max + 3), dtype=np.uint32)\n",
    "    \n",
    "    icm_csr_matrix[tracks,albums_id] = 1\n",
    "    icm_csr_matrix[tracks, albums_max + artists_id] = 1\n",
    "    icm_csr_matrix[tracks, albums_max + artists_max + durations] = 1\n",
    "    \n",
    "    return icm_csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_durations(data):\n",
    "    data.loc[tracks['duration_sec'].isin(range(60)),'duration_sec'] = 1\n",
    "    data.loc[tracks['duration_sec'].isin(range(60,120)), 'duration_sec'] = 2\n",
    "    data.loc[tracks['duration_sec'].isin(range(120,180)), 'duration_sec'] = 3\n",
    "    data.loc[tracks['duration_sec'].isin(range(180,240)), 'duration_sec'] = 4\n",
    "    data.loc[tracks['duration_sec'].isin(range(240,300)), 'duration_sec'] = 5\n",
    "    data.loc[tracks['duration_sec'].isin(range(300,200000)), 'duration_sec'] = 6\n",
    "\n",
    "    data['duration_sec'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "#Raggruppiamo per playlist_id, le celle conterranno il count() del gruppo, quindi il numero di canzoni per playlist\n",
    "grouped = train.groupby('playlist_id')['track_id'].nunique()\n",
    "\n",
    "#Prendiamo le playlist che superano il numero di elementi del TEST_SET_THRESHOLD\n",
    "clipped = grouped.index[grouped>TEST_SET_THRESHOLD].tolist()\n",
    "\n",
    "#Adesso prendiamo a caso degli indici di playlist in percentuale di TEST_SET_HOLDOUT\n",
    "#ATTENZIONE, la percentuale viene calcolata sulla lunghezza di clipped, che avrà un numero di elementi inferiore a train\n",
    "#Questo significa che il 20% di clipped sarà circa il 14% del train, la percentuale è da aggiustare tenendo conto di sto fatto\n",
    "test_set_indices = [ clipped[i] for i in sorted(random.sample(range(len(clipped)), int(TEST_SET_HOLDOUT*len(clipped)))) ]\n",
    "\n",
    "#Andiamo a estrarre dal train TUTTE le canzoni delle playlist estratte a sorte nella riga prima\n",
    "test_groups = train.loc[train['playlist_id'].isin(test_set_indices)]\n",
    "\n",
    "#Andiamo a creare un dataframe vuoto, a cui appenderemo tutte le canzoni da ficcare nel test_set con una .append()\n",
    "test_set = pd.DataFrame(columns=[\"playlist_id\",\"track_id\"])\n",
    "\n",
    "#Per ogni gruppo prendiamo le ultime 10 canzoni e le appendiamo al test_set\n",
    "for name, group in test_groups.groupby('playlist_id'):\n",
    "    test_set = test_set.append(group.tail(10))\n",
    "    \n",
    "#Togliamo le canzoni del test set al train, salvandolo in una nuova variabile \n",
    "#Questo è solo un trick per fare la differenza insiemistica\n",
    "training_set = pd.concat([train, test_set, test_set]).drop_duplicates(keep=False)\n",
    "\n",
    "#Ora passiamo training_set e test_set a csr_matrix\n",
    "urm_csr = build_urm_csr(training_set)\n",
    "test_set_csr = build_urm_csr(test_set)\n",
    "icm_csr = build_icm_csr(tracks)\n",
    "\n",
    "test_set_playlists = test_set['playlist_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
